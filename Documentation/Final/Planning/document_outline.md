<head>
  <link rel="stylesheet" href="style.css">
</head>
# Project outline

Total word count: ~10000 words

Title: Deep Learning Model Performance Comparason for the Categorisation of Galaxy Morphology

## Abstract

100-250 Words
outline the aims, purpose of the project, the results gathered and conclusion

purpose: Facilitate astronomers in categorising galaxies for their studies on morphology distribution
aims: train a variety of ML models on a dataset from GZ2 images and labels.
results+conclusion: show which deep learning model works the best on unseen data (generalised well)

## Contents

LaTeX autogenerated

## Intro

500-750 words

Introduction should be adapted from project proposal

## Literature review

~1000 words

Same for LR
Expand on similar studies.

## Requirements analysis
[RADocs](https://docs.google.com/document/d/1bmVOOpZHJzcxhcpnQ3ZAYDfpt9L8AWOANYOUxr2sAPE/edit)
1600-1700 **Satisfied**: 2272

Aims, Objectives and Technologies
Also adapted from project proposal but expand on technologies that are used.

Technologies:

- Programming:
  - Python
  - Pylance

- Dataset loading and cleaning:
  - Pyspark 
  - Pandas

- Maching Learning
  - TensorFlow
  - Keras

- Visualisation
  - Seaborn (Rapper for Matplotlib)

## Design & Methodology
[DMDocs](https://docs.google.com/document/d/177a5n4F58Qt4l_Y-6Q_b_h7ko0QUqlKRTqlRGj2L8C4/edit)
1600-1700

Broad overview of the whole project

- Project Management:
  - Jupyter
  - GitHub

- Software Deployment:
  - Using CUDA to allow fast model training

- Model Choices:
  - Deep learning + backproperagation
  - AlexNet (baseline)
  - Resnet (testing multiple depths)
  - Convnext (Once Implemented)
  - Optamisation (Adam)

- Programming Style:
  - Functional
  - Array Oriented
  - Typed

- Statistical Analysis:
  - Why I'm using F1 and Accuracy, (The model doesn't need to prioritise T-N or F-P)
  - Running Models Multiple Times For average accuracy

## Implementation
1600-1700

More detail on how I used the technology from requirements and applied my methodologies:

- How did I load and preprocess the data?
- How did I make my program more concise and generalised with FP?
- What were my runtime efficiency considerations?
- How does my model implementations compare to the official Keras models?
- Where could I improve?

## Results
1600-1700

Explanation of what my results were and what I did to collect them.
Displaying results.

## Conclusions
1600-1700

Comparason of different model performance:

  - How well do the models generalise?
  - What do different model evaluation heuristics show?

Comparasons to other studies:

  - Where were the shortcomings of my models?

